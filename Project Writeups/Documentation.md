# Documentation 

### Modules
The final model creation framework, in its current incarnation, consists of three central components; the image/data handler, the model generation and evaluation software, and the live predictor used in downstream processing. The functionality and purpose of each of these components within our framework is outlined below [DEVNOTE: add screenshots to descs.]
* ##### <a name="imagereader"></a> Component 1: Image and Data Handling Module (`imagereader.py`)
This is a library of functions used for all image reading, manipulation, storage, and display needed for models. Broadly speaking, the data sets fed into our model programs are stored as sets of images with corresponding csv file containing the name of each image and its associated disease label (elaborated further in [input](#input). This library was originally had the sole purpose of reading these image folders and csv's, but was continually expanded to encompass more broad usage over time. The utilities within are often general purpose, with a counterpart function specific to our use immediately following each. The functions as listed here are accompanied by screenshots and "TRIP" descriptions which are laid out as follows:
* #### `{name of function}`
- **Takes**: <input arguments enumerated>
- **Returns**: <function outputs enumerated>
- **Internal References**: <name(s) of function(s) from this library that are referenced, (accompanied by the depth of reference in parenthesis)* >
- **Purpose**: <brief description of the use of the function, the problem it is created to solve, or the history of its necessity in our program>
  *Note that the reference depth for all functions not listed is implicitly 0

Descriptions below:
1. #### <a name="read_image_data_pairs"></a> `read_image_data_pairs()`
- **Takes**: the name of a csv in our [input](#input) folder as a string 
- **Returns**: a list containing pairs of disease bools and image IDs for each data entry.
- **Internal References**: None
- **Purpose**: providing the relevant image names and labels of a dataset for other functions in this library to use 
2. #### <a name="get_all_Bools"></a>`get_all_Bools()`
- **Takes**: the name of a csv in our [input](#input) folder and optional boundary conditions (default to length of csv if unspecified)
- **Returns**: a list only containing the disease bools, in order within the boundary conditions
- **Internal References**: [read_image_data_pairs()](#read_image_data_pairs)(1)
- **Purpose**: providing a specific set of data disease labels to model training and data labelling functions
3. #### <a name="read_all_images"></a>`read_all_images()`
- **Takes**: the name of an image folder, the name of a csv (both names as strings WITHOUT a file extension and both of the files being referenced being located in our [input](#input) folder), optional resizing dimensions (default to None if neither or only one is specified), optional boundary conditions (behave as prior), and an optional mute argument (0 or 1 taken)
- **Returns**:  a list of arrays of numerical image data, in order within the boundary conditions; if resizing dimensions are specified, the image data returned with be resized from the original size (6000x4000 in our case) to the new dimensions. If mute is disabled, the function will also print out read progress during parsing, the amount and size of images read after parsing, and the time taken to parse
- **Internal References**: [read_image_data_pairs()](#read_image_data_pairs)(1)
- **Purpose**: converting image names into their respective image data for use in model training and display programs, enables resizing from any arbitrarily sized image set to a specified size, (i.e. 256x256 in particular for use in our model) 
4. #### <a name="images_to_pickle"></a>`images_to_pickle()`
- **Takes**: the path of where the new file should be created, a name for the new file, the name of the folder the images are currently in, the name of the associated csv (both being within the [input](#input) folder), and optional resizing dimensions, optional boundary conditions, and an optional mute argument (all optional arguments behave as prior).
- **Returns**:  creates a pickle file, storing the images specified, at the specified path and named the specified name. If mute is disabled, will print out the image read progress, the number and shape of the images read, and the name of the new file the time taken to create it upon completion, or will yield a duplication warning and if a file of the specified name in the specifed directory already exists (the function will also cease running if this is the case).
- **Internal References**: [read_all_images()](#read_all_images)(1), [read_image_data_pairs()](#read_image_data_pairs)(2)
- **Purpose**: Direct image reading takes a significant amount of time in practice (has O(n) time complexity, from observation); for our larger data sets, direct read times ranged from 25-40 minutes, which is neither conducive to a development schedule nor to user convenience. Because the sets being trained over are essentially static and will need to be read arbitrarily many times, the simplest solution was to do a one-time lengthy read of the images into a compact and quickly accessible file and to then read those images from the file. We initially tried the .hdf5 format, but found that it was time and memory bottleneck, and eventually discovered what we needed within cPickle. This function facilitates creating the .pickle upon initial read, but can also be used more broadly for making any image set into a .pickle.
5. #### <a name="make_pickle"></a>`make_pickle()`
- **Takes**: the name referring to a data set, optional boundary conditions, and an optional mute argument
- **Returns**: a new pickle file (called '<name of the data set>_imgs.pickle') inside our [pickles](#pickles) folder. If mute is disabled, will output printouts which are the same as [images_to_pickle()](#images_to_pickle).
- **Internal References**: [images_to_pickle()](#images_to_pickle)(1), [read_all_images()](#read_all_images)(2), [read_image_data_pairs()](#read_image_data_pairs)(3)
- **Purpose**: One of the specified counterpart functions mentioned prior, intended as a extended simplification of the [images_to_pickle()](#images_to_pickle) function for our use. This function produces all the relevant respective file names (under our paradigm) for a given dataset and passes these names to the [images_to_pickle()](#images_to_pickle) function, effectively reducing the creation of new pickle files to providing the name of the dataset being pickled.
6. #### <a name="parity_balance"></a>`parity_balance()`
- **Takes**: an arbitrary list, and a list of equal length containing some boolean mapping of the first
- **Returns**: two lists which match the two lists taken but are truncated such that there are an equal number of items mapped to one boolean value as there to the other; mapping on an individual basis is preserved and returned in order. The members of a set which are truncated is chosen randomly and will differ in successive runs over the same set, however, there will always be a 50/50 boolean distribution after balancing.
- **Internal References**: None
- **Purpose**: a source of concern we had, upon researching machine learning data cleaning techniques, was that our sub-par results were caused, in some part, by the uneven distribution of our plant data; across all our data sets, there were between twofold and fourfold as many sick examples as there were healthy ones. To test whether this was a factor, this function was created to even the distribution of the data while preserving the labels associated with each image. Originally this was a dedicated function for this purpose, but was later generalized and referenced more specifically in the [get_features_and_labels()](#get_features_and_labels) function because this balancing paradigm seemed useful for other, future data applications and for pure mathematical curiosity.
7. #### <a name="get_features_and_labels"></a>`get_features_and_labels()`
- **Takes**: the name referring to a dataset, an optional balance argument, an optional mute argument, and optional boundary conditions
- **Returns**: a list of arrays of numerical image data from the specified dataset, and a list of disease booleans associated with the returned images. If balance is enabled, the number of diseased and Healthy images will be balanced as set forth in the [parity_balance()](#parity_balance) function. Will automatically create a new .pickle file (via the [make_pickle()](#make_pickle) function) upon initial read of a data set, this takes trivially longer than the required direct read upon first-time image 
- **Internal References**: [parity_balance()](#parity_balance)(1), [get_all_Bools()](#get_all_Bools)(1), [read_all_images()](#read_all_images)(2), [read_image_data_pairs()](#read_image_data_pairs)(2, 3)
- **Purpose**: This function is intended as a be-all-end-all function for fetching image datasets to feed into a model; it combines functionality from all the major data getting and reshaping functions within this library and presents them in a compact format for ease of use, configuration, and experimentation while creating models, allowing more time to be spent optimizing a model rather than manipulating data. If the files constituting a dataset are present in [input](#input) and are properly named, this function can utilise that dataset within all further code, with the only input necessary being the name of the dataset.
8. #### <a name="adaptive_graph"></a>`adaptive_graph()`
- **Takes**: a list of numerical image data of the pictures to be displayed, a list of the titles associated with the images input(in the same order as those images), the number of columns across which the picture grid is to be displayed
- **Returns**: displays a rectangular grid plot of images made from the image data, in the order given, with the titles given attached and resized to display all images as compactly as possible, of the given width and of a length long enough to accomodate the whole set. If `None` is passed as the 'titles' argument, the pictures will be graphed with no titles.
- **Internal References**: None
- **Purpose**: at several distinct points throughout evaluating the model performance during development, there arose the need to be able to visually inspect the results of the models predictions on a moderately large scale en masse, in a clearly labelled and visually understandable way; this need was either dismissed or circumvented by means such as labelling and exporting the images in question ([fakecheck](#modelgen)), but to better meet that need in other/future utilities, this graphing function was created as a general purpose clean image graph creator. Examples of use can be seen the the [auggrapher](#modelgen)
9. #### <a name="preview_crops"></a>`show_crops()`
- **Takes**: the name referring to a dataset, the number of columns across which the picture grid is to be displayed, an optional balance argument, optional boundary conditions, and an optional mute argument (note that mute in this particular instance has little effect, as printouts are only ever present upon a first-time read of the files being displayed)
- **Returns**: a rectangular grid plot of the crop images read, in the same manner of format as [adaptive_graph()](#adaptive_graph), with the appropriate "Healthy" of "sick" title attached to each image
- **Internal References**: [adaptive_graph()](#adaptive_graph)(1), [get_features_and_labels()](#get_features_and_labels)(1), [parity_balance()](#parity_balance)(2), [get_all_Bools()](#get_all_Bools)(2), [read_all_images()](#read_all_images)(3), [read_image_data_pairs()](#read_image_data_pairs)(3, 4)
- **Purpose**: Continuing with the theme of other function pairs in this library, this function is just an extension of the adaptive grapher specific to our use; this function can be used as essentially an image set previewer over arbitrary slices of any image set in our [input](#input) folder, to inspect images and labels for correctness before training.

* ##### <a name="modelgen"></a> Module 2:  Model Generator (`Plant_Disease_Model_Creator.ipynb`)
[WIP, did not have the time to finish this portion of the documentation, however, heavily commented screenshots of all of the model generator code can be found within the "Report Pictures" folder in this folder, will eventually add those here and annotate then on a cell-by-cell basis]

* ##### <a name="predictor"></a> Module 3: Standalone/Live Predictor (`Live_Predictor.ipynb`)
- **Takes:** Images placed within the folder containing this module, any pretrained model file (taken from)
- **Returns:** Periodically returns a dictionary with the names of the images currently in the folder as keys and the their predicted disease values as keys
- **Internal References:** The model file and images within the folder containing the predictor. Note that these are not references to functions or other code within the predictor, but to files which are necessary for the predictor to be able to function that are carried around with it (the sets of files within the predictor folder together constitute the actual gestalt predictor, just as the image and label csv files from prior together constitute a complete dataset, the whole is greater than the sum of it parts')
- **Purpose:** It recreates, as minimalistically as possible, the models layers used in training, imports and compiles the chosen model from the [models](#models) folder, and then runs indefinitely, periodically updating and returning an internal dictionary with the names of the images currently within its folder and their associated prediction value. The folder containing this predictor is completely transplantable, as long as the predictor can be accessed in jupyter, takes any pretrained model from our [models](#models), as long as you specify the model contained, and updates dynamically as images are added or removed while running, ultimately sending the prediction data to a MongoDB database to be utilised in our front-end application.

## Non-Code Files
In addition to the software, many files are also present that are necessary for proper functionality. These are divided amongst four folders, which are described here by their contents and use within our framework.
* #### <a name="input"></a> Folder 1: Input
**Contains:** All datasets which are available fed for model for training and/or evaluation. At the present, this consists of a control sample dataset, along with 'boom', 'drone', and handheld sets. Apart from the sample dataset, a labelled dataset within our framework is represented by a folder (called "images_<name of dataset>") containing the images that make up that dataset, and a csv file (called "labels_<name of dataset>.csv") containing indexed labels of the images in said folder, in order (each row of the csv contains the name of an image file and its corresponding label, currently True or False for Blight or Healthy, respectively).
**Use:** This folder is meant as a means of organising and keeping track of the data fed to the [model generator](#modelgen). Adding new data into our framework is very straightforward and only requires creating the appropriate labels csv and naming the dataset files as outlined above; from there, the data can be referenced by the name of the set as a whole throughout the reading and model creation software with no further setup required.
* #### <a name="pickles"></a> Folder 2: Pickles
**Contains:**  Pickle files storing all the images from datasets currently in the [input](#input) folder which have at some point been read. All files are name {name of dataset}_imgs.pickle.
**Use:** This folder is vital to speedy and efficient functioning of any part of the software which handles images, particularly model generation. A .pickle file essentially stores a large list of data as a relatively short (and memory efficient) string which can be re-made into the data it represents quickly and on demand. Because the direct reading times of even our current, relatively small, datasets on our high-performance computer are generally beyond half an hour, a .pickle file of a datasets images is made upon initially reading of that dataset (via the [make_pickle()](#make_pickle) function)to avoid lengthy wait times beyond that initial reading; the images can then be rapidly and readily read and used by the rest of the software.
* #### <a name="fakes"></a> Folder 3: Fakes
**Contains:** The images that have been wrongly categorised by the predictor in the previous training session, with each image being labelled with its position in the set predicted over, the prediction value it was assigned, and the time at which the image was created. This folder only populates during a training session if 'export' is enabled in the `document_mistakes()` function.
**Use:** This folder exists purely as a diagnostic repository and was implemented to replace the previous method of viewing false predictions,  displaying them all with the [adaptive_graph()](#adaptive_graph) function, as the sets of incorrect images range in order of magnitude from hundreds to thousands even with our relatively small datasets.
* #### <a name="models"></a> Folder 4: Assorted Models
**Contains:** Pre-trained models created by the [model generator](#modelgen) that have been preserved; also contains the associated individual weights files for each model as well, though these do not currently have a use in our paradigm. All model and weight files are labelled according to the conditions they were trained in (names contain the data set name, data modifications, and hyperparameters from that session) to facilitate reproducibility and evaluation of successful model creation conditions.
**Use:** Each model file in this folder can be inserted into a [predictor](#predictor) program folder and specified within the predictor, where it can then be used to then evaluate live streams of crop data. This functionality represents the integration between our model generation software and downstream processing. 



