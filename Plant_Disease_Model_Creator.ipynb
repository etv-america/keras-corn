{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras image classification development\n",
    "#### This is a binary image classification test on corn with leaf blight and healthy corn; \n",
    "#### We are training using drone images from Cornell University \n",
    "#### ---------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "# To Do for model development:\n",
    "\n",
    "## Broad/long-term goals\n",
    "\n",
    "- [ ] Figure out classifications beyond binary\n",
    "- [ ] Implement 'meta-tuner' to optimize hyperparams automatically\n",
    "- [ ] Try to build our model atop a pre-made model\n",
    "\n",
    "## Immediate/short-term goals\n",
    "\n",
    "- [ ] Tweak hyperparameters, see how to add decay, momentum, etc. (optimizer-dependent)\n",
    "- [ ] Add/reshape model layers to enhance training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "#  basic modules \n",
    "import random, datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#  image and display utilities\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "#  our custom modules\n",
    "import imagereader as ir\n",
    "\n",
    "#  file/data utilities\n",
    "import os, shutil\n",
    "import _pickle as cPickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc  #  Garbage collector for cleaning redundant data from memory\n",
    "\n",
    "#  supressing deprecation warnings\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: The cell below contains all the preprocessing for the sample data set; if you have no use for the sample data then you can skip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "#  create sample image sets from the specified folders; this code as is from Kaggle, with optimizations for our usage\n",
    "list_all = lambda dirname: ['./Input/sample_dataset/' + dirname +'{}'.format(i) for i in os.listdir('./Input/sample_dataset/' + dirname)]\n",
    "#  path to folder containing sample data ^^^ ; change path here if necessary\n",
    "\n",
    "#  create sample training sets from directories\n",
    "train_healthy = list_all('train_corn/healthy/')\n",
    "train_spot = list_all('train_corn/spot/')\n",
    "train_rust = list_all('train_corn/rust/')\n",
    "train_blight = list_all('train_corn/blight/')\n",
    "#  create sample test sets from directories\n",
    "test_healthy = list_all('test_corn/healthy/')\n",
    "test_spot = list_all('test_corn/spot/')\n",
    "test_rust = list_all('test_corn/rust/')\n",
    "test_blight = list_all('test_corn/blight/')\n",
    "\n",
    "#  isolate and create blight and healthy sets for our particular model training \n",
    "train_imgs = train_blight + train_healthy\n",
    "random.shuffle(train_imgs)\n",
    "\n",
    "test_imgs = test_blight + test_healthy \n",
    "random.shuffle(test_imgs)\n",
    "\n",
    "def read_and_process_samples(list_of_images, image_location, nrows=256, ncolumns=256):\n",
    "    x, y = [], []\n",
    "    for image in list_of_images:\n",
    "        x.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows, ncolumns), interpolation=cv2.INTER_CUBIC))\n",
    "        if image in image_location:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    y = [not i for i in y]  #  disease labelling in sample data is inverted, compared to our own\n",
    "    return x, y\n",
    "\n",
    "#  Processing the training sample images\n",
    "x, y = read_and_process_samples(train_imgs, train_healthy)\n",
    "\n",
    "#  Processing the test sample images\n",
    "x_test, y_test = read_and_process_samples(test_imgs, test_healthy)\n",
    "\n",
    "#  formatting the training sample data\n",
    "x_sample, x_val1, y_sample, y_val1 = train_test_split(x, y, test_size=0.2) \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 6,663,873\n",
      "Trainable params: 6,663,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  setting up keras utilities and model layers\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import metrics  #  adding the built-in metrics to better gauge model veracity\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 16} )\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# TODO: add/reshape model layers\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = models.Sequential()  #  model is created\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(256, 256, 3))) #  image size taken by model in initial layer\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))  #Dropout for regularization\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  #Sigmoid function at the end because we have just two classes\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP! Configure model settings below before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  !!CRITICAL FOR FUNCTIONALITY!! - Establish settings for model input and training\n",
    "\n",
    "#  training data selection\n",
    "set_content_source = 'all'  #  specify which kind of set(s) to be trained over (ours, sample, mixed, or all)\n",
    "set_content = 'drone'  #  specify which one of the non-sample image sets is to be read (handheld, drone, or boom), irrelevant if using only sample data or all \n",
    "\n",
    "#  data manipulation/reshaping\n",
    "augment_traindata = True  #  determine level of augmentation of data; accuracy/speed tradeoff for True/False, respectively\n",
    "balance_data = False #  optionally, even out how many healthy and unhealthy data points there are in our set (only affects our data, not the sample YET)\n",
    "                     #  PROGNOTE: negative performance impact seems to be attributable to reduced sample size and pseudo-random distribution, not mismatch\n",
    "\n",
    "#  configuration of hyperparameters\n",
    "batch_size = 32  #  32 seems best suited for our data sizes, investigate further to confirm\n",
    "nr_epochs = 4\n",
    "learn_rate = 1e-4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  All reading and formatting of the model input data is done in this cell; split freely if finer debugging is needed\n",
    "\n",
    "\n",
    "#  control for reading our chosen set    \n",
    "if set_content_source == 'ours' or set_content_source == 'mixed':   \n",
    "    if os.path.exists('./Input/images_' + set_content) == True and os.path.exists('./Input/labels_{}.csv'.format(set_content)) == True:\n",
    "        #  the above checks that there exist files which constitute a valid data set of the name specified\n",
    "        pictures, blightvals = ir.get_features_and_labels(set_content, balance=balance_data)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(pictures, blightvals, test_size=0.2)  #  splitting the image data into train and validation sets\n",
    "        print('Images input from the %s set'%set_content)\n",
    "    else:\n",
    "        print('Invalid/Incomplete set specified')\n",
    "elif set_content_source == 'sample':\n",
    "    print('Training over sample data, skipping image file input')\n",
    "elif set_content_source == 'all':  \n",
    "    dataset_files, complete_datasets = os.listdir('./Input'), []\n",
    "    for i in dataset_files:  #  gets the names of all the complete datasets currently in 'Inputs' (apart from sample)\n",
    "        if i.split('_')[0] == 'images' and os.path.exists('./Input/labels_%s.csv'%i.split('_')[1]):\n",
    "            complete_datasets.append(i.split('_')[1])\n",
    "    discrete_data = [ir.get_features_and_labels(dataset) for dataset in complete_datasets]  #  combined pictures and labels for all complete sets\n",
    "    random.shuffle(discrete_data)  #  mix for better model variety, parity is preserved via tuples\n",
    "    pictures, blightvals = [pic for single_set in discrete_data for pic in single_set[0]], [bbool for single_set in discrete_data for bbool in single_set[1]]\n",
    "    #  list comprehensions which unpack the picture and blightbool sets from the now random combined set ^^^\n",
    "    x_train, x_val, y_train, y_val = train_test_split(pictures, blightvals, test_size=0.2)  #  splitting the image data into train and validation sets\n",
    "    print('Found and input %d complete sets: '%len(complete_datasets), complete_datasets)\n",
    "else:\n",
    "    print(\"No set specified\")\n",
    "\n",
    "#  control for which images/data are selected to be trained over\n",
    "def merge_and_shuffle(set1, set2):  #  merges two sets into a single training set, used when 'mixed' set is chosen\n",
    "    modelset = set1 + set2\n",
    "    random.shuffle(modelset)\n",
    "    return modelset\n",
    "\n",
    "if set_content_source == \"ours\" or set_content_source == \"all\":  #  training and evaluating over our data\n",
    "    pass\n",
    "elif set_content_source == \"sample\":  #  training and evaluating over the sample data\n",
    "    x_train = x_sample\n",
    "    x_val = x_val1\n",
    "    y_train = y_sample\n",
    "    y_val = y_val1\n",
    "    feat, lab = x_test, y_test\n",
    "elif set_content_source == \"mixed\":\n",
    "    x_train = merge_and_shuffle(x_train, x_sample)  #  mixing the two data sets \n",
    "    x_val = merge_and_shuffle(x_val, x_val1)  #  (has significantly less favorable performance due to visual disparity in images)\n",
    "    y_train = merge_and_shuffle(y_train, y_sample)\n",
    "    y_val = merge_and_shuffle(y_val, y_val1)\n",
    "    feat, lab = pictures + x_test, blightvals + y_test\n",
    "else:\n",
    "    print(\"No data loaded\")\n",
    "\n",
    "#  convert to arrays (train generator flow doesn't take lists)\n",
    "x_train, y_train, x_val, y_val = np.array(x_train), np.array(y_train), np.array(x_val), np.array(y_val)\n",
    "\n",
    "#  data sizes, for diagnostics and for setting model step size (below)\n",
    "ntrain, nval = len(x_train), len(y_train)\n",
    "print(' \\nFull input set size: %d'%(ntrain + len(x_val)),\"\\nTraining set size: %d\"%ntrain,\"\\nValidation set size: %d\"%len(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  All image generation and augmentation prep is done in this cell\n",
    "\n",
    "\n",
    "#  create the image augmentation generators used in the model training\n",
    "if augment_traindata == False:\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)   #  only rescales, does not modify images fed\n",
    "elif augment_traindata == True:\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,   #  rescale = scaling brightness, not size\n",
    "                                        rotation_range=40,\n",
    "                                        #width_shift_range=0.2,\n",
    "                                        #height_shift_range=0.2,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True,\n",
    "                                        fill_mode=\"reflect\")  #  tweak augment features at will\n",
    "else:\n",
    "    print(\"No augmentation setting specified\")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  #  Only ever rescales the validation data, for a true measure of model accuracy\n",
    "\n",
    "\n",
    "#  establish data generators and model optimizer \n",
    "train_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(x_val, y_val, batch_size=batch_size)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Nadam(lr=learn_rate), metrics=['acc'])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The actual training; adjust hyperparameters in the initial settings cell to tweak model performance\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = ntrain // batch_size,\n",
    "                              epochs=nr_epochs,\n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = nval // batch_size)\n",
    "\n",
    "\n",
    "\n",
    "#  Saving the generated model locally; checks for model files and rewrites, if necessary\n",
    "if os.path.isfile('model_complete.hd5') == True:  #  model overwrite procedure\n",
    "    os.remove('model_complete.hd5')\n",
    "os.mknod('model_complete.hd5')\n",
    "\n",
    "if os.path.isfile('model_weights.hd5') == True:  #  weights overwrite procedure\n",
    "    os.remove('model_weights.hd5')\n",
    "os.mknod('model_weights.hd5')\n",
    "\n",
    "#  Save the model\n",
    "model.save_weights('model_weights.hd5')  #  saving files\n",
    "model.save('model_complete.hd5')\n",
    "\n",
    "\n",
    "\n",
    "#  Plotting the train and val progress of the model\n",
    "extrametric = None #'mean_absolute_error'\n",
    "\n",
    "#  define accuracy, and optionally another metric (which must be set before training in model.compile(...), located at the end of the reading stage)\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc'] \n",
    "if extrametric != None:\n",
    "    extra1 = history.history[extrametric]\n",
    "    extra2 = history.history['val_' + extrametric]  #originally just 'val' and 'val_acc', option to add metrics\n",
    "#  loss, constant definition\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#  Plotting accuracies, and optionally another metric\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "if extrametric != None:\n",
    "    plt.plot(epochs, extra1, 'y', label='Training ' + extrametric)\n",
    "    plt.plot(epochs, extra2, 'g', label='Validation ' + extrametric)\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "#  Plotting losses\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  specify the set which the model is to be evaluated over (!NOTE!: must be a labelled data set)\n",
    "\n",
    "if set_content_source != 'sample':\n",
    "    feat, lab = ir.get_features_and_labels('boom', balance=False, start=4000, end=8000)\n",
    "print(len(feat), len(lab))  #  personal check for whether the correct data has been loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  predicts over the specified labelled data, then identifies, labels, and exports false predictions\n",
    "def document_mistakes(features, labels, export=True):\n",
    "    print(\"Predicting...\", end=\"\\r\")  #  predicting over chosen set, create list of predictions\n",
    "    results = model.predict(np.array(features))\n",
    "    print(\"Done Predicting\", end=\"\\r\")\n",
    "    predictions = []\n",
    "    for val in results:\n",
    "        predictions.append(int(round(val[0])))\n",
    "\n",
    "    fps, labelz = [], {1:\"Sick\", 0:\"Healthy\"}  #  isolate false predictions based on their example label\n",
    "    for i in range(len(labels)-1):\n",
    "        if predictions[i] != labels[i]:\n",
    "            fps.append(i)\n",
    "\n",
    "    #  display amount of results that are false predictions\n",
    "    print(\"False Predictions in %d%% of the data (%d fakes)\" % (100*len(fps)//len(labels), len(fps)))\n",
    "\n",
    "    #  export false evaluations to fakes folder\n",
    "    if export == True:\n",
    "        print('Exporting labelled fakes...', end='\\r')\n",
    "        if os.path.exists(\"./Fakes\") == True:  # empty out old fakes\n",
    "            shutil.rmtree(\"./Fakes\")\n",
    "        os.mkdir(\"Fakes\")\n",
    "        \n",
    "        time = lambda a: datetime.datetime.now().strftime(a)\n",
    "        for i, val in enumerate(fps):\n",
    "            plt.imsave(\"./Fakes/image{}-flagged:{}@{}.png\".format(val, labelz[predictions[val]], time(\"%X\")), features[val])\n",
    "        print('Finished Exporting fakes    ')\n",
    "\n",
    "#  made as function so this code can be recycled for evaluation in future model frameworks\n",
    "document_mistakes(feat, lab, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  option to preserve the current model, along with weights file, for future predictions if results are favorable\n",
    "preserve = True\n",
    "\n",
    "if preserve == True:\n",
    "    model.save('./Assorted Models/%dep-%s(%sbal, %saug), lr=%1.2e, bs=%d_model.h5'%\n",
    "        (nr_epochs, set_content, 'un'*int(not balance_data), 'un'*int(not augment_traindata), learn_rate, batch_size))\n",
    "    model.save_weights('./Assorted Models/%dep-%s(%sbal, %saug), lr=%1.2e, bs=%d_weights.h5'%\n",
    "        (nr_epochs, set_content, 'un'*int(not balance_data), 'un'*int(not augment_traindata), learn_rate, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Test and display model prediction over generated images based on the training set; \n",
    "#  less useful over non-sample data, as it is hard to tell from cursory visual inspection whether or not the prediction is accurate\n",
    "\n",
    "#  Configure augmentation settings for the generated evaluation images\n",
    "test_datagen = ImageDataGenerator(rescale=1./300,\n",
    "                                  rotation_range=0,\n",
    "                                  width_shift_range=0.0,\n",
    "                                  height_shift_range=0.0,\n",
    "                                  shear_range=0.0,\n",
    "                                  zoom_range=0.0,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=False,\n",
    "                                  fill_mode=\"constant\",\n",
    "                                  cval=12)\n",
    "\n",
    "def show_predictions(columns, total_images):  #  Displays the predictions much like ir.show_crops(), only with the length explicitly specified     \n",
    "    text_labels, gen_imgs, i = [], [], 0\n",
    "    for batch in test_datagen.flow(np.array(random.sample(x_train, total_images)), batch_size=1):  #  generates images based on training set\n",
    "        gen_imgs.append(np.squeeze(batch, axis=0))                             #  NOTE: random sample improves variety, slicing saves memory\n",
    "        pred = model.predict(batch)\n",
    "        if pred > 0.5:\n",
    "            text_labels.append('blighted')\n",
    "        else:\n",
    "            text_labels.append('Healthy')\n",
    "        i += 1\n",
    "        if i == total_images:\n",
    "            break\n",
    "    ir.adaptive_graph(gen_imgs, text_labels, columns)  #  neatly formats and displays the produced images and labels\n",
    "            \n",
    "show_predictions(9, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
