{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras image classification development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a binary image classification test on corn with leaf blight and healthy corn; \n",
    "#### We are training using sample images from Kaggle and drone images from Cornell University \n",
    "#### ---------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": false
   },
   "source": [
    "# To Do for model development:\n",
    "\n",
    "## Broad/long-term goals\n",
    "\n",
    "- [ ] Add/reshape model layers\n",
    "- [ ] Figure out classifications beyond binary\n",
    "- [ ] Add and tweak decay, momentum, etc. hyperparameters\n",
    "- [ ] Further research and evaluate optimizer types\n",
    "- [ ] Try to build our model atop a pre-made model\n",
    "\n",
    "## Immediate/short-term goals\n",
    "\n",
    "- [ ] Use data from \n",
    "- [ ] Finish cleaning this code for ease of running, accessibility, and configuring training settings\n",
    "- [ ] Manipulate saved model weights rather than retraining each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "#  basic modules \n",
    "import random, datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  image and display utilities\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "#  our custom modules\n",
    "import imagereader as ir\n",
    "\n",
    "#  file utilities\n",
    "import os, shutil\n",
    "import h5py\n",
    "import gc # Garbage collector for cleaning deleted data from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "#  create sample image sets from the specified folders\n",
    "list_all = lambda dir: [dir+'{}'.format(i) for i in os.listdir(dir)]\n",
    "\n",
    "train_healthy = list_all('./input/dataset/train_corn/healthy/')\n",
    "train_spot = list_all('./input/dataset/train_corn/spot/')\n",
    "train_rust = list_all('./input/dataset/train_corn/rust/')\n",
    "train_blight = list_all('./input/dataset/train_corn/blight/')\n",
    "\n",
    "test_healthy = list_all('./input/dataset/test_corn/healthy/')\n",
    "test_spot = list_all('./input/dataset/test_corn/spot/')\n",
    "test_rust = list_all('./input/dataset/test_corn/rust/')\n",
    "test_blight = list_all('./input/dataset/test_corn/blight/')\n",
    "\n",
    "#  Create blights/healthy sets for ours model training\n",
    "train_imgs = train_blight + train_healthy\n",
    "random.shuffle(train_imgs)\n",
    "\n",
    "test_imgs = test_blight + test_healthy \n",
    "random.shuffle(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_image(list_of_images, image_location, nrows=256, ncolumns=256):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for image in list_of_images:\n",
    "        x.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows, ncolumns), interpolation=cv2.INTER_CUBIC))\n",
    "        \n",
    "        if image in image_location:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "            \n",
    "    return x, y\n",
    "\n",
    "#  Processing the training sample images\n",
    "x, y = read_and_process_image(train_imgs, train_healthy)\n",
    "#print(\"Shape of train images is: {}\\nShape of Labels is {}\".format(x.shape, y.shape))\n",
    "\n",
    "#  Processing the test sample images\n",
    "x_test, y_test = read_and_process_image(test_imgs, test_healthy)\n",
    "#print(\"Shape of train images is: {}\\nShape of Labels is {}\".format(x_test.shape, y_test.shape))\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "columns = 5\n",
    "for i in range(columns):\n",
    "    print(\"Image at\",i,\"is a\", y[i])\n",
    "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
    "    plt.imshow(x[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(y)\n",
    "plt.title('Labels for Healthy and Blight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Suppressing Deprecation warnings\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    \n",
    "#  setting up keras utilities and model layers\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess= tf.Session(config=config)\n",
    "\n",
    "# TODO: add/reshape model layers\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model = models.Sequential()  #  model first created\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(256, 256, 3))) #  image size taken by model\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))  #Dropout for regularization\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  #Sigmoid function at the end because we have just two classes\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Establish settings for training data creation and formatting\n",
    "augment_traindata = True  #  determine level of augmentation of data; accuracy/speed tradeoff for True/False respectively\n",
    "read_method = \"from_file\" #  Direct read is highly not recommended due to time and memory overhead, write to file with ir and read from file instead\n",
    "training_set_content = \"sample\"  #  specify which set is trained over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create the image transformation generators used in the model training\n",
    "if augment_traindata == False:\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "elif augment_traindata == True:\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,   #  Scale the brightness\n",
    "                                        rotation_range=40,\n",
    "                                        #width_shift_range=0.2,\n",
    "                                        #height_shift_range=0.2,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True,\n",
    "                                        fill_mode=\"reflect\")\n",
    "else:\n",
    "    print(\"No augmentation setting specified\")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  #  Only ever rescale the validation data for true measure of model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if read_method == \"from_file\":\n",
    "    f = h5py.File('./cropdata-U8.hdf5', 'r+')  # !METHOD 1! - reading our corn image data from the static file\n",
    "    pictures = list(f.get('pics')[()])         #  READTIME is trivial if there is free memory\n",
    "    f.close()                              \n",
    "elif read_method == \"direct\":\n",
    "    pictures = ir.read_all_images(x=256, y=256)  #  !METHOD 2! - reading our corn image data directly from the image folders. READTIME: exactly 4mins\n",
    "else:\n",
    "    print(\"No images read\")\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blightvals = ir.get_all_Bools()  #  <-- NOTE: This always reads the bools directly; \n",
    "                                 #  if reading from the static image file, make sure that the file reflects current data before running\n",
    "#  formatting our image data\n",
    "x_train, x_val, y_train, y_val = train_test_split(pictures, blightvals, test_size=0.2) \n",
    "\n",
    "#  formatting the sample data\n",
    "x_sample, x_val1, y_sample, y_val1 = train_test_split(x, y, test_size=0.2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create set to be trained over\n",
    "def merge_and_shuffle(set1, set2):  #  combines and shuffles a list and nparray (respectively) and  returns a combined array\n",
    "    modelset = set1 + set2\n",
    "    random.shuffle(modelset)\n",
    "    return modelset\n",
    "\n",
    "if training_set_content == \"ours\":  #  training and evaluating over our data\n",
    "    x_training = x_train\n",
    "    x_valid = x_val\n",
    "    y_training = y_train\n",
    "    y_valid = y_val\n",
    "    feat, lab = pictures, blightvals\n",
    "elif training_set_content == \"sample\":  #  training and evaluating over the sample data\n",
    "    x_training = x_sample\n",
    "    x_valid = x_val1\n",
    "    y_training = y_sample\n",
    "    y_valid = y_val1\n",
    "    feat, lab = x_test, y_test\n",
    "elif training_set_content == \"mixed\":\n",
    "    x_training = merge_and_shuffle(x_train, x_sample)  #  mixing the two data sets \n",
    "    x_valid = merge_and_shuffle(x_val, x_val1)  #  (has less favorable performance due to disparity in images)\n",
    "    y_training = merge_and_shuffle(y_train, y_sample)\n",
    "    y_valid = merge_and_shuffle(y_val, y_val1)\n",
    "    feat, lab = pictures + x_test, blightvals + y_test\n",
    "else:\n",
    "    print(\"No data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain, nval = len(x_training), len(y_training)\n",
    "batch_size = 32  #  set batchsize\n",
    "print(ntrain + len(x_valid),\"\\n\", ntrain,\"\\n\", len(x_valid))\n",
    "\n",
    "#Create the image generators\n",
    "train_generator = train_datagen.flow(np.array(x_training), np.array(y_training), batch_size=batch_size)\n",
    "val_generator = val_datagen.flow(np.array(x_valid), np.array(y_valid), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Place to tweak classification type, Learn rate, and Optimizer type\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The training part; adjust hyperparameters (in two cells above and current cell) to tweak model performance\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = ntrain // batch_size,\n",
    "                              epochs=4,\n",
    "                              validation_data = val_generator,\n",
    "                              validation_steps = nval // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Check if files exist and rewrite if they do\n",
    "if os.path.isfile('model_keras.h5') == True:\n",
    "    os.remove('model_keras.h5')\n",
    "os.mknod('model_keras.h5')\n",
    "\n",
    "if os.path.isfile('model_weights.h5') == True:\n",
    "    os.remove('model_weights.h5')\n",
    "os.mknod('model_weights.h5')\n",
    "\n",
    "#  Save the model\n",
    "model.save_weights('model_weights.h5')\n",
    "model.save('model_keras.h5')\n",
    "\n",
    "#  from keras.models import load_model & load_model(<modelname>)  - (loads pretrained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting the train and val progress\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "#Train and validation accuracy\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "#Train and validation loss\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Personal Code for testing for false evaluations over test data; feat and lab defined when selecting model input data\n",
    "def document_mistakes(features, labels):\n",
    "    print(\"Predicting...\", end=\"\\r\")\n",
    "    results = model.predict(np.array(features))\n",
    "    print(\"Done Predicting\", end=\"\\r\")\n",
    "    predictions = []\n",
    "    for val in results:\n",
    "        predictions.append(int(round(val[0])))\n",
    "\n",
    "    fps, names, labelz = [], [], {1:\"Healthy\", 0:\"Sick\"}\n",
    "    for i in range(len(labels)-1):\n",
    "        if predictions[i] != labels[i]:\n",
    "            fps.append(i)\n",
    "            names.append(labelz[predictions[i]])\n",
    "\n",
    "    #  code for displaying false predictions\n",
    "    print(\"False Predictions in %d%% of the data, exporting %d fakes...\" % (100*len(fps)//len(labels), len(fps)))\n",
    "    \n",
    "    #  cleanout files with each new run\n",
    "    if os.path.exists(\"./fakes\") == True:\n",
    "        shutil.rmtree(\"./fakes\")\n",
    "    os.mkdir(\"fakes\")\n",
    "    \n",
    "    #  export false evaluations to fakes folder\n",
    "    time = lambda a: datetime.datetime.now().strftime(a)\n",
    "    for i, val in enumerate(fps):\n",
    "        plt.imsave(\"./fakes/fakeid{}-flagged:{}@{}.png\".format(val, names[i], time(\"%X\")), features[val])\n",
    "    \n",
    "document_mistakes(feat, lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Test and display model prediction over generated images based on the training set\n",
    "\n",
    "#  Configure augmentation settings for the generated evaluation images\n",
    "test_datagen = ImageDataGenerator(rescale=1./300,\n",
    "                                  rotation_range=0,\n",
    "                                  width_shift_range=0.0,\n",
    "                                  height_shift_range=0.0,\n",
    "                                  shear_range=0.0,\n",
    "                                  zoom_range=0.0,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=False,\n",
    "                                  fill_mode=\"constant\",\n",
    "                                  cval=12)\n",
    "\n",
    "def show_predictions(columns, total_images):  #  Displays the specified amount of augmented data and predictions in given number of rows\n",
    "    all_images = x_training#training image reference      \n",
    "    all_images = all_images[:total_images]\n",
    "    text_labels, i = [], 0\n",
    "    plt.figure(figsize=(30,20))\n",
    "    for batch in test_datagen.flow(np.array(all_images), batch_size=1):\n",
    "        pred = model.predict(batch)\n",
    "        if pred > 0.5:\n",
    "            text_labels.append('Healthy')\n",
    "        else:\n",
    "            text_labels.append('damaged')\n",
    "        plt.subplot(((total_images-1)//columns)+1, columns, i+1)\n",
    "        plt.title(text_labels[i])\n",
    "        plt.axis(\"off\")\n",
    "        imgplot = plt.imshow(batch[0])\n",
    "        i += 1\n",
    "        if i % total_images == 0:\n",
    "            break\n",
    "            \n",
    "show_predictions(5, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This first ever working run with Keras is promising and is reminiscent of what other first run projects have produced.\n",
    "Some of the spikes in loss of accuracy could be attributed to bad data. Further investigation and tuning needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
